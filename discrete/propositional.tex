%\setchapterpreamble[u]{%
%}
\chapter{Propositional calculus}
\label{ch:propositional}

In this chapter we will encounter a system,
called \definitionintro{propositional calculus},
\marginnote{This isn't the same ``calculus'' as in common usage.
  Here, ``calculus'' comes from the Latin word for ``pebble'',
  which was once used for counting.\cite{wiktionary-calculus}}
for reasoning about things and determining whether they are true or false.

\section{Propositions and truth}
\label{sec:propintro}

Not every conceivable sentence has a definite truth value.
For example, consider:
\begin{center}
  Shakespeare was a great playwright.
\end{center}
You might disagree with the sentiment---and certainly, for all his fame,
Shakespeare's ``greatness'' is a matter of some subjectivity.
On the other hand, we may assert the truth value of certain things:
\begin{center}
  This sentence is composed of words.
\end{center}
Those sentences to which we can assign a truth value will be called
\definitionintro{propositions}.
Such that our reason is not muddied by the details of language and subjectivity,
we will introduce \definitionintro{variables} to which we may assign these propositions.
This will be our first dealing with the tool of mathematical abstraction---the ability
to separate the process of reason from the objects of reason,
and this will greatly expand our power of thought.
We will see that through reason we can find truths far greater and more
universal than any individual happening, once sufficient abstraction
and logic have laid the groundwork for thought.

It helps to be systematic about things.
While intuition is a powerful trick, it only carries us so far:
rigor is needed to go the rest of the way.
As such, many definitions I will label explicitly.

\begin{defn}[proposition]
A \definition{proposition}{proposition} is a sentence that makes a statement
and has a truth value.
\end{defn}

\begin{ex}
  The following sentence is a proposition:
  \begin{equation}
    \text{``My house is red.''}
    \label{eq:ex:proposition}
  \end{equation}
  The way we know that \eref{eq:ex:proposition} is a proposition is because
  it has a theoretically knowable truth value.

  If we agree that we may assign a symbol to mean the same thing as
  \eref{eq:ex:proposition},
  such that everywhere we write
  \begin{equation*}
    \text{``My house is red.''}
  \end{equation*}
  we could have just as well written that symbol, then that symbol is called
  a \definitionintro{propositional variable}.
  The most formal way we may assert such an assignment is by writing
  a sentence like the following:
  \begin{equation}
    \text{Let $p$ be ``My house is red.''}
    \label{eq:propostional-symbolic-notation}
  \end{equation}
  Given an assignment like \eref{eq:propostional-symbolic-notation},
  we call the symbol $p$ a \definition{propositional variable}{propositional variable},
  and the sentence ``My house is red'' its \definition{value}{value}.
  We will then write that $p$ is \ltrue{} if my house is, indeed,
  red---or that $p$ is \lfalse{} if that is not the case.
\end{ex}

In most systems of mathematics, there are certain conventions for variables.
In propositional calculus, the first variable we will often use is $p$, followed
by $q$, then $r$, $s$, and then whatever feels convenient if we have used up
all of those.
\marginnote{Generally speaking, smaller letters mean ``lesser'' abstraction, so $P$ is
more abstract than $p$, and fancier fonts like $\mathscr{P}$ are more abstract
than even $P$.
This is just a rule of thumb, of course, so don't take it for granted.}

The simplest thing we can do next is \definitionintro{negation}.
If we can propose the truth of some propositional variable $p$,
we just as well may propose the alternative!
\begin{defn}[negation]
  Let $p$ be a proposition.
  The \definition{negation}{negation} $\neg p$ of $p$
  is the statement
  ``it is not the case that \(p\).''
  The truth value of \(\neg p\) is the opposite of the truth value of \(p\).
  \label{defn:propositional-negation}
\end{defn}

\newcommand{\lawofmiddle}{Law of Excluded Middle}
Before we go further, it's worth mentioning something we're taking for granted:
the \axiomintro{\lawofmiddle{}}:
\begin{quote}
  For the proposition `it may be' implies a twofold possibility, while, if either of the two former propositions is true, the twofold possibility vanishes. For if a thing may be, it may also not be, but if it is necessary that it should be or that it should not be, one of the two alternatives will be excluded. It remains, therefore, that the proposition `it is not necessary that it should not be' follows from the proposition `it may be'. For this is true also of that which must necessarily be.\cite{aris-interp}
\end{quote}
This axiom, proposed by Aristotle, is still taken to be valid by most mathematicians today---though there is a ``minority school of mathematicians,'' called Intuitionists, who ``do precisely that.''\cite{trudeau}

Regardless, we will take it to be self-evident that the \lawofmiddle{} holds, and move on with more interesting things.

\begin{ex}
  Let $p$ be ``my house is red.''
  Then $\neg p$ is
  ``it is not the case that my house is red,''
  or simply
  ``my house is not red.''
\end{ex}

The symbol $\neg$ in \defnref{defn:propositional-negation} is called a \definitionintro{unary operator}. Operators are things that act on variables or other symbols, called their \definition{operands}{operand}. A \definition{unary operator}{unary operator} is an operator that has only one operand.

We also have \definition{binary operators}{binary operator}, like \definitionintro{conjunction}, which work on two operands:
\begin{defn}[conjunction]
  Let $p$ and $q$ be propositions.
  The \definition{conjunction}{conjunction}
  $p \wedge q$
  of $p$ and $q$,
  is the proposition
  ``$p$ and $q$.''
  The conjunction is \ltrue{} when both $p$ and $q$ are \ltrue{} and \lfalse{} otherwise.
\end{defn}
The conjunction operator $\wedge$ is an example of a binary operator.
The number of operands for an operator is call its \definition{arity}{arity}.
\begin{ex}
  Let $p$ be ``Kevin likes Sarah'' and let $q$ be ``Sarah likes Kevin.'
  Then $p \wedge q$ is
  ``Kevin likes Sarah and Sarah likes Kevin,''
  or ``Kevin and Sarah like each other.''
  This statement would be \lfalse{} if either of the two did not like the other.
\end{ex}

\begin{defn}[disjunction]
  Let $p$ and $q$ be propositions.
  The \definition{disjunction}{disjunction}
  of $p$ and $q$,
  written $p \vee q$,
  is the proposition
  ``$p$ or $q$.''
  It is \ltrue{} when either $p$ or $q$ are \ltrue{} and \lfalse{} otherwise.
\end{defn}

\begin{ex}
  Let $p$ denote ``Kevin hates bagels'' and
  $q$ be the assertion that ``Kevin hates poppy seeds.''
  The proposition $p \vee q$ is the statement ``Kevin hates bagels or poppy seeds.''
  \begin{remark}
    Note, here, that there is an implicit cue in the language that Kevin could,
    indeed, hate both bagels and poppy seeds.
    The statement would be \ltrue{} if he were distasteful toward either one of them,
    or both. In \exref{ex:prop:xordefn} we will see language cues toward the
    other usage of English \emph{or}.
  \end{remark}
\end{ex}

\begin{defn}[exclusive or]
  The \definition{exclusive or}{exclusive or}
  $p \oplus q$
  of propositional variables
  $p$ and $q$ is \ltrue{} when exactly one of $p$ and $q$ is \ltrue{},
  and \lfalse{} otherwise.
\end{defn}

\begin{ex}
  Let $p$ mean ``I could sleep in all day today''
  and $q$ mean ``I could go to work.''
  Then the statement $p \oplus q$ is \ltrue{} when only one of $p$ or $q$ is \ltrue{}.
  It is the sentence ``I could go to work, or I could sleep in all day today.''
  Since it does not make sense to do both at once,
  the \definitionintro{exclusive or} is implied by our choice of words.
  \begin{remark}
    We should keep an eye out for this distinction between disjunction and
    exclusive or, as it requires careful attention to the subtleties in our use of
    language.
  \end{remark}
  \label{ex:prop:xordefn}
\end{ex}

\begin{defn}[conditional statement]
  The \definition{conditional statement}{conditional statement}
  \begin{equation}
    p \implies q
    \label{eq:propositional:conditional}
  \end{equation}
  is the proposition ``if p, then q.''
  It is \lfalse{} when $p$ is \ltrue{} and $q$ is \lfalse{}, and \ltrue{} otherwise.
  \label{def:conditional}
\end{defn}

In such a conditional statement,
we say that $q$ is \definitionintro{necessary} for $p$,\index{necessary}
and that $p$ is \definitionintro{sufficient} for $q$.\index{sufficient}
The intuition here is that if $p$ is \ltrue{}, then $q$ is definitely \ltrue{},
but the truth of $q$ does not imply the truth of $p$.

\begin{defn}[hypothesis]
  In a conditional statement, $p$ is called the \definition{hypothesis}{hypothesis}
  (or \altdefinition{antecedent}{antecedent} or \altdefinition{premise}{premise}).
\end{defn}

\begin{defn}[conclusion]
  In a conditional statement, the variable $q$ is called the \definition{conclusion}{conclusion}
  or \altdefinition{consequence}{consequence}.

  Other ways of writing the conditional statement are shown in \tabref{tab:conditionals}.
\end{defn}

\begin{ex}
  Let $p$ be ``Joe broke his arm''
  and let $q$ be ``Joe will go to the hospital.''

  If one were to state that $p \implies q$, they mean
  ``If Joe broke his arm, then he will go to the hospital.''
  This conditional is \ltrue{} if Joe only goes to the hospital,
  if he only breaks his arm, and if both events occur.
  The only situation in which it is \lfalse{} is if Joe breaks his arm,
  but does not go to the hospital.
\end{ex}

\begin{table}[H]
  \centering
    \begin{tabular}{p{2in} p{2in}}
      ``if \(p\), then \(q\)''                     & ``\(p\) implies \(q\)'' \\
      ``if \(p\), \(q\)''                          & ``\(p\) only if \(q\)'' \\
      ``\(p\) is sufficient for \(q\)''            & ``a sufficient condition for \(q\) is \(p\)'' \\
      ``\(q\) if \(p\)''                           & ``\(q\) whenever \(p\)`` \\
      ``\(q\) when \(p\)''                         & ``\(q\) is necessary for \(p\)'' \\
      ``a necessary condition for \(p\) is \(q\)'' & ``\(q\) follows from \(p\)'' \\
      ``\(q\) unless \(p\)''
    \end{tabular}
  \caption{Other ways of writing the conditional statement \(p \implies q\).}
  \label{tab:conditionals}
\end{table}

\begin{defn}[converse]
  The \definition{converse}{converse} of \(p \implies q\) is \(q \implies p\).
\end{defn}

\begin{defn}[contrapositive]
  The \definition{contrapositive}{contrapositive} of
  \eqref{eq:propositional:conditional}
  is the propositional statement
  \begin{equation}
    \neg q \implies \neg p.
    \label{eq:propositional:contrapositive}
  \end{equation}
  \label{def:contrapositive}
\end{defn}

\begin{theorem}
  The contrapositive statement
  \eqref{eq:propositional:contrapositive}
  is logically equivalent to the conditional statement
  \eqref{eq:propositional:conditional}.
  \label{thm:contrapositive-conditional}
\end{theorem}

\thref{thm:contrapositive-conditional} is the first example we have seen
of a mathematical statement that asserts something about the mathematical
constructs we have presented thus far.
When we make such an assertion, it is useful to demonstrate that our assertion
holds some clout.
To this end, we will introduce the notion of \definitionintro{truth tables}.

\begin{defn}
  A \definition{truth table}{truth table} shows all of the possible values
  of the propositional variables in at least one propositional statement,
  and the respective values of those propositional statements when those
  variables take on such values.

  Truth tables can be used to demonstrate the logical relationships between
  statements and demonstrate some useful property about those relationships.
\end{defn}

\begin{proof}[\thproofref{thm:contrapositive-conditional}]
  We will prove \thref{thm:contrapositive-conditional} using a truth table.
  \begin{table}[H]
    \centering
    \begin{tabular}{llrr}
      \toprule
      $p$ & $q$ & $p\implies q$ & $\neg q \implies \neg p$\\
      \midrule
      \lfalse{} & \lfalse{} & \ltrue{} & \ltrue{} \\
      \lfalse{} & \ltrue{} & \ltrue{} & \ltrue{} \\
      \ltrue{} & \lfalse{} & \lfalse{} & \lfalse{} \\
      \ltrue{} & \ltrue{} & \ltrue{} & \ltrue{} \\
      \bottomrule
    \end{tabular}
    \caption{A truth table for $p\implies q$ and $\neg q \implies \neg p$.}
    \label{tab:contrapositive}
  \end{table}
  In \tabref{tab:contrapositive}, we have shown that for all
  possible values of $p$ and $q$,
  the conditional statement $p \implies q$
  holds the same truth value as the contrapositive statement
  $\neg q \implies \neg p$.
\end{proof}

This property of contrapositives is especially useful when we are trying to prove a statement,
as its contrapositive is often easier to prove than the statement itself.
This subject is detailed further in \secref{sec:contrapositive}.

\begin{defn}[inverse]
  The \definition{inverse}{inverse} of
  the conditional statement
  \eqref{eq:propositional:conditional}
  is
  \begin{equation}
    \neg p \implies \neg q,
    \label{eq:propositional:inverse}
  \end{equation}
  and it has the opposite truth value of the original statement.
\end{defn}

\begin{defn}
  The \definition{biconditional statement}{biconditional statement},
  (also called \altdefinition{bi-implication}{bi-implication})
  for $p$ and $q$ is the statement that is \ltrue{}
  when both $p$ and $q$ have the same truth value,
  and \lfalse{} otherwise.
  The biconditional is written
  \begin{equation}
    p \iff q
    \label{eq:propositional:biconditional}
  \end{equation}
  and means
  ``$p$ if and only if $q$.''
\end{defn}

\begin{table}[h]
  \centering
    \begin{tabular}{l}
      ``\(p\) is necessary and sufficient for \(q\)'' \\
      ``if \(p\), then \(q\), conversely'' \\
      ``p iff q''
    \end{tabular}
  \label{tab:biconditionals}
\end{table}
In mathematical theorems, definitions, and related elements later in this text, we will often see the biconditional operator written \emph{iff}.

\begin{defn}[compound proposition]
A \definition{compound proposition}{compound proposition}
is a proposition that can be broken down into simpler propositions.
\end{defn}

We will sometimes refer to compound propositions with a capital letter,
like $P$ instead of $p$ or $Q$ instead of $q$, when we wish to emphasize
that $P$ and $Q$ are compound propositions.
However, this is just a general rule---the context will usually make it
clear which form of proposition we are discussing.

\begin{defn}[logical equivalence]
The compound propositions $P$ and $Q$ are
\definition{logically equivalent}{logical equivalence}
if $P \iff Q$ is a tautology.
We will write
\begin{equation}
  P \equiv Q
\end{equation}
to mean that $P$ and $Q$ are logically equivalent.
\end{defn}

\begin{remark}
  The symbol \(\equiv\) is not a logical connection, and \(p\equiv q\) is not a compound proposition, but rather it is the statement that \(p \iff q\) is a tautology. While $\iff$ is an operator applied to propositional variables, $\equiv$ is an operator on entire propositional statements.
\end{remark}

\begin{defn}[tautology]
  A \definition{tautology}{tautology} is a compound proposition
  that is always \ltrue{}, regardless of the truth values of the
  variables that occur in it.
\end{defn}

\begin{defn}[contradiction]
  A \definition{contradiction}{contradiction} is a compound proposition
  that is always \lfalse{}.
\end{defn}

\begin{defn}[contingency]
  A \definition{contingency}{contingency} is a compound proposition
  that is neither a tautology nor a contradiction.
  It can be either \ltrue{} or \lfalse{}.
\end{defn}

\begin{theorem}
The biconditional statement \eqref{eq:propositional:biconditional}
is logically equivalent to
\begin{equation}
(p \implies q) \wedge (q \implies p).
\end{equation}

That is,
\begin{equation}
p \iff q \equiv (p \implies q) \wedge (q \implies p).
\label{eq:biconditional-equivalence}
\end{equation}
\label{th:biconditional-equivalence}
\end{theorem}

\begin{proof}[\thproofref{th:biconditional-equivalence}]
We will prove this by truth table.
\begin{table}[H]
  \centering
    \begin{tabular}{llrrrr}
      \toprule
      $p$ & $q$ & $p \implies q$ & $q \implies p $ & $(p \implies q) \land (q \implies p)$ & $p \iff q$ \\ \midrule
      \lfalse{} & \lfalse{} & \ltrue{}      & \ltrue{}             & \ltrue{}  & \ltrue{}    \\
      \lfalse{} & \ltrue{} & \ltrue{}      & \lfalse{}             & \lfalse{}  & \lfalse{}    \\
      \ltrue{} & \lfalse{} & \lfalse{}      & \ltrue{}             & \lfalse{}  & \lfalse{}    \\
      \ltrue{} & \ltrue{} & \ltrue{}      & \ltrue{}             & \ltrue{}  & \ltrue{}    \\
      \bottomrule
    \end{tabular}
  \caption{Truth table proof of \thproofref{th:biconditional-equivalence}.}
  \label{tab:propositional:proof:bicond-equiv}
\end{table}
Since the last two columns in
\tabref{tab:propositional:proof:bicond-equiv}
have the same truth value, we can be certain that
\eqref{eq:biconditional-equivalence}
holds.
\end{proof}

%\begin{table}[H]
%  \centering
%    \begin{tabular}{lrcccc}
%      \toprule
%      $p$ & $q$ & $\neg q$ & $p \lor \neg q$ & $p \land q$ & $(p \lor \neg q) \implies (p \land q)$ \\ \midrule
%      1 & 1 & 0      & 1             & 1         & 1 \\
%      1 & 0 & 1      & 1             & 0         & 0 \\
%      0 & 1 & 0      & 0             & 0         & 1 \\
%      0 & 0 & 1      & 1             & 0         & 0 \\
%      \bottomrule
%    \end{tabular}
%  \caption{The truth table for $(p \lor \neg q) \implies (p \land q)$}
%\end{table}

\section{Precedence}
For more complex propositions, we need rules to tell which logical operators come first when we read them.

The \emph{not} operator ($\neg$) takes the highest precedence.
Then conjunction ($\land$), followed by disjunction ($\lor$).
Then conditional ($\implies$), and finally bi-conditional ($\iff$) operators.
\begin{table}[H]
  \centering
    \begin{tabular}{lll}
      \toprule
      precedence & symbol & meaning \\ \midrule
      1 & $\neg$      &not\\
      2 & $\land$     &and \\
      3 & $\lor$      & or \\
      4 & $\implies$  & conditional \\
      5 & $\iff$      &biconditional
      \\ \bottomrule
    \end{tabular}
  \caption{Logical operator precedence.}
  \label{tab:precedence}
\end{table}
\begin{ex}
    Is the statement $ p \land q \lor r $ equivalent to the statement
    \begin{enumerate}
        \item[a.] $(p \land q ) \lor r$,
        \item[b.] or rather, to $ p \land (q \lor r)$?
    \end{enumerate}
    \begin{sol}
        Let's look at \tabref{tab:precedence}.
        It states that $\land$ (``and'') operators come before $\lor$ (``or'') operators.
        Therefore,
        \[ p \land q \lor r \equiv (p \land q) \lor r,\]
        and (a) is the correct answer.
    \end{sol}
\end{ex}

\section{DeMorgan's Laws}
\definitionintro{DeMorgan's Laws} are an important concept in propositional
logic and boolean algebra.\index{DeMorgan's Laws}

\begin{defn}[DeMorgan's Laws]
\definition{DeMorgan's Laws}{DeMorgan's Laws} state that:
\begin{equation}
  \neg (p \land q) \equiv \neg p \lor \neg q
\end{equation}
\begin{equation}
  \neg(p \lor q) \equiv \neg p \land \neg q
\end{equation}
\end{defn}
These can be proven using a \textbf{truth table}.
In order to construct a truth table, we must display all possible values of the propositional variables,
and the corresponding values of the propositional statement for each combination.
Intermediary steps may aid one's understanding, though they are not necessary in the final result.
\begin{table}[H]
  \centering
    \begin{tabular}{lrcc}
      \toprule
      $p$ & $q$ & $\neg(p \land q)$ & $\neg p \lor \neg q$ \\ \midrule
      0 & 0 & 1 & 1 \\
      0 & 1 & 1 & 1\\
      1 & 0 & 1 & 1\\
      1 & 1 & 0 & 0\\
      \bottomrule
    \end{tabular}
  \caption{A proof of DeMorgan's first law.}
\end{table}

\begin{table}[H]
  \centering
    \begin{tabular}{lrcc}
      \toprule
      $p$ & $q$ & $\neg(p \lor q)$ & $\neg p \land \neg q$ \\ \midrule
      0 & 0 & 1 & 1 \\
      0 & 1 & 0 & 0 \\
      1 & 0 & 0 & 0 \\
      1 & 1 & 0 & 0 \\
      \bottomrule
    \end{tabular}
  \caption{A proof of DeMorgan's second law.}
\end{table}

Extending DeMorgan's laws by the association laws for disjunction and conjunction, shown in \tabref{tab:logequiv}, they become:
\begin{equation}
 \neg\left(\bigwedge^n_{n=1} p_n\right)=\bigvee^n_{n=1} \neg p_n
\end{equation}
\begin{equation}
 \neg\left(\bigvee^n_{n=1} p_n\right)=\bigwedge^n_{n=1} \neg p_n
\end{equation}
Using DeMorgan's Laws, we can \emph{negate conjunctions and disjunctions}.
In computer science, we use DeMorgan's Laws to simplify boolean expressions.

\begin{ex}
  Negate the following statement:
  ``Miguel has a cellphone and he has a laptop.''
  \begin{sol}
    Let \(p\) be ``Miguel has a cell phone.''
    Let \(q\) be ``Miguel has a laptop.''
    The negation of $p \land q$ is
    \[ \neg p \lor \neg q, \]
    which means ``Miguel does not have a cell phone or he does not have a laptop.''
  \end{sol}
\end{ex}

\section{Useful Logical Equivalences}

In a proof or simplification of propositional logic statements, propositions like $p \implies q$
are difficult for us to work with.
We have very few laws or equivalences which work directly with them, so we often must convert them into an equivalent form using other operators.


We can convert $p\implies q$ to a proposition using only the $\neg$ and $\lor$ operators using the logical equivalence
\begin{equation}
  p \implies q \equiv \neg p \lor q,
\end{equation}
which we will prove using a truth table in \tabref{tab:conditionalproof}.
\begin{table}[H]
  \centering
    \begin{tabular}{lrcc}
      \toprule
      $p$ & $q$ & $p \implies q$ & $\neg p \lor q$ \\ \midrule
      1 & 1 & 1 & 1 \\
      1 & 0 & 0 & 0 \\
      0 & 1 & 1 & 1 \\
      0 & 0 & 1 & 1 \\
      \bottomrule
    \end{tabular}
  \caption{A proof of \(p \implies q \equiv \neg p \lor q\).}
  \label{tab:conditionalproof}
\end{table}

\begin{table}[H]
  \centering
    \begin{tabular}{lr}
      \toprule
      \textbf{Proposition} & \textbf{Name} \\ \midrule
      $p \land T \equiv p$ & \multirow{2}{*}{identity laws} \\
      $p \lor f \equiv p $ \\\midrule
      $p \lor T \equiv T $ & \multirow{2}{*}{domination laws} \\
      $p \land F \equiv F $ \\\midrule
      $p \lor p \equiv p $ & \multirow{2}{*}{idempotent laws} \\
      $p \land p \equiv p $ \\\midrule
      $\neg (\neg p) $ & double negation law \\ \midrule
      $p \lor q \equiv q \lor p $ & \multirow{2}{*}{commutative laws} \\
      $p \land q \equiv q \land p $ \\ \midrule
      $(p \lor q) \lor r \equiv p \lor (q \lor r) $& \multirow{2}{*}{associative laws} \\
      $(p \land q) \land r \equiv p \land (q \land r)$  \\\midrule
      $p \land (q \lor r) \equiv (p \land q) \lor (p \land r)$ & \multirow{2}{*}{distributive laws} \\
      $p \lor (q \land r) \equiv (p \lor q) \land (p \lor r)$ \\\midrule
      $\neg (p \lor q) \equiv \neg p \lor \neg q $ & \multirow{2}{*}{DeMorgan's laws} \\
      $\neg (p \lor q) \equiv \neg p \land \neg q $ \\\midrule
      $p \lor (p \land q) \equiv p $ & \multirow{2}{*}{absorbtion laws} \\
      $p \land (p \lor q) \equiv p $ \\\midrule
      $p \lor \neg p \equiv T $ & \multirow{2}{*}{negation laws} \\
      $p \land \neg p \equiv F $
    \end{tabular}
  \caption{Useful logical equivalence laws.}
  \label{tab:logequiv}
\end{table}

\section{Proving Logical Equivalences}

We can prove logical equivalences by using the rules in \tabref{tab:logequiv}, and showing
how one step leads to another until we reach something we know to be \ltrue{}.
Alternatively, we could start with a statement that we know to be \ltrue{} and work our way to the logical equivalence we are trying to prove.
Both of these proof methods are valid, though not especially rigorous, as they rely upon rules that we may not have established the truth value of with the mathematical rigor required to consider them \emph{formal proofs}.
\begin{ex}
  Show that \(\neg (p \implies q)\) and \( p \land \neg q\) are logically equivalent.
  \begin{sol}
    \[
      \begin{fitch}
        \fb \neg (p \implies q) \equiv \neg (p \implies q) \\
        \fa \neg(p \implies q) \equiv \neg(\neg p \lor q) & \(p \implies q \equiv \neg p \lor q\) \\
        \fa \neg(p \implies q) \equiv \neg(\neg p) \land \neg q & \text{DeMorgan's Law} \\
        \fa \neg(p \implies q) \equiv p \land \neg q & \text{Double negation}
      \end{fitch}
    \]
  \end{sol}
\end{ex}

Alternatively, they can be proven using truth tables, as described in \secref{def:contrapositive}.

% \section{Bit Operations}
%
% These logical operators can also be performed on \textbf{bits} (0 is \lfalse{}, 1 is \ltrue{}).
% These are called \textbf{bit operations}, and can even be performed on \textbf{bit strings}, sequences of zero or more bits.
% The \textbf{length} of a bit string is the number of bits in the string.
% \begin{ex}
%   Perform bitwise OR, AND, and XOR operations on the following bit strings.
%   \begin{align*}
%     01 \, 1011 \, 0100 & \\
%     11 \, 0001 \, 1101 &
%   \end{align*}
%   \begin{sol}
%     \begin{align*}
%       01 \, 1011 \, 0100 & \\
%       11 \, 0001 \, 1101 &
%       \\ \\
%       11 \, 1011 \, 1111 & \quad \text{bitwise OR} \\
%       01 \, 0001 \, 0100 & \quad \text{bitwise AND} \\
%       10 \, 1010 \, 1011 & \quad \text{bitwise XOR}
%     \end{align*}
%   \end{sol}
% \end{ex}

% \section{Examples}
%
% % bad example, copied from a textbook.
% % I need to write my own.
% \begin{ex}\cite[p.~14]{rosen}
%   Determine whether each of these conditional statements is \ltrue{} or \lfalse{}.
%   \begin{itemize}
%     \item[a) ] if \(1+1=2\), then \(2+2=5\)
%     \item[b) ] if \(1+1=3\), then \(2+2=4\)
%     \item[c) ] if \(1+1=3\), then \(2+2=5\)
%     \item[d) ] if monkeys can fly, then \(1+1=3\)
%   \end{itemize}
%   \begin{sol}
%     In each case, we simply determine the truth value of the hypothesis and the conclusion, then use the definition of the truth value of conditional statements to get our answer.
%     \begin{itemize}
%       \item[a) ] The hypothesis is \ltrue{}, and the conclusion is \lfalse{}, so the statement is \lfalse{}.
%       \item[b) ] Since the hypothesis is \lfalse{} and the conclusion is \ltrue{}, the statement is \ltrue{}.
%       \item[c) ] Since the hypothesis is \lfalse{}, regardless of the conclusion the conditional statement must be \ltrue{}.
%       \item[d) ] Since the hypothesis is \lfalse{}, the conditional is \ltrue{}.
%     \end{itemize}
%   \end{sol}
% \end{ex}

\section{Propositional Satisfiability}
% I'm pretty sure this section is ripped near-straight from a textbook too.
% I really need to write my own.

A compound proposition is \textbf{satisfiable} if there is an assignment of truth values to its variables that make it \ltrue{}.
When no such assignments exists, it is \textbf{unsatisfiable}.
A particular assignment of truth values that shows a compound proposition satisfiable is a \textbf{solution}.

To show a compound proposition is satisfiable, we need only demonstrate one possible solution.
However, to demonstrate it unsatisfiable, we would need to show every possible assignment of truth values and show why they make it \lfalse{}.
Thus, reasoning is often more useful than truth tables in showing a compound proposition is unsatisfiable.

% \begin{ex}
%   Determine whether each of the following is satisfiable.
%   \begin{itemize}
%     \item[a) ] \( (p \lor \neg q) \land (q \lor \neg r) \land (r \lor \neg p) \)
%     \item[b) ]  \((p \lor q \lor r) \land (\neg p \lor \neg q \lor \neg r) \)
%     \item[c) ]  \( (p \lor \neg q) \land (q \lor \neg r) \land (r \lor \neg p) \land (p \lor q \lor r) \land (\neg p \lor \neg q \lor \neg r)\)
%   \end{itemize}
%   \begin{sol}
%     (a) is \ltrue{} when \(p\), \(q\) and \(r\) have the same truth value.
%     (b) is \ltrue{} when at least one of \(p\), \(q\), or \(r\) is \lfalse{} and one is \ltrue{}.
%     So (c), a combination of (a) and (b), is unsatisfiable.
%   \end{sol}
% \end{exK

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../notes"
%%% End: 
